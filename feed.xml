<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2023-10-26T20:31:02+02:00</updated><id>/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
</subtitle><entry><title type="html">Pyraug Case Study 1</title><link href="/2021/07/12/pyraug.html" rel="alternate" type="text/html" title="Pyraug Case Study 1" /><published>2021-07-12T00:00:00+02:00</published><updated>2021-07-12T00:00:00+02:00</updated><id>/2021/07/12/pyraug</id><content type="html" xml:base="/2021/07/12/pyraug.html"><![CDATA[<h2 id="case-study-1-classification-on-3d-mri-adni--aibl">Case Study 1: Classification on 3D MRI (ADNI &amp; AIBL)</h2>

<h3 id="introduction">Introduction</h3>

<p align="justify" style="text-align:justify"> 
A Riemannian Hamiltonian VAE model <d-cite key="chadebec_geometry-aware_2020"></d-cite> and <a href="https://github.com/clementchadebec/pyraug" target="blank">Pyraug software</a> were used to perform Data Augmentation in the High Dimensional Low Sample Size Setting on 3D MRI neuroimaging data from <a href="http://adni.loni.usc.edu/" target="blank">ADNI database</a>. The model was used to try to enhance the classification task consisting in finding Alzheimer's disease patients (AD) from Cognitively Normal participants (CN) using T1-weighted MR images <d-cite key="chadebec_data_2021"></d-cite>.  such augmentation.
</p>

<h3 id="classification-set-up">Classification set up</h3>

<h4 id="data-splitting">Data Splitting</h4>

<p align="justify">The ADNI data set was split into 3 sets: train, validation and test.
First, the test set was created using 100 randomly chosen participants for each diagnostic label (i.e. 100 CN, 100 AD). The rest of the data set was split such that 80% is allocated from training and 20% for validation. The authors ensured that age, sex and site distributions between the three sets were not significantly different. The train set is referred to as <i>train-full</i> in the following.

In addition, a smaller training set (denoted as <i>train-50</i>) was extracted from <i>train-full</i>. This set comprised only 50 images per diagnostic label, instead of 243 CN and 210 AD for <i>train-full</i>. It was ensured that age and sex distributions between <i>train-50</i> and <i>train-full</i> were not significantly different. This was not done for the site distribution as there are more than 50 sites in the ADNI data set (so they could not all be represented in this smaller training set). The AIBL data was <b>never used for training</b> or hyperparameter tuning and was only used as an <b>independent</b> test set.
</p>
<div class="img">
    <div class="col-sm mt-0 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/pyraug_project/Case_study_1.jpg" alt="" title="Data Splitting" />
    </div>
</div>
<div class="caption">
     Data Split for the classification task: Alzheimer Disease (AD) vs. Cognitively Normal (CN)
</div>

<h4 id="data-processing">Data Processing</h4>

<p>All the data was processed as follows:</p>
<dl>
  <li> Raw data are converted to the BIDS standard <d-cite key="gorgolewski_brain_2016"></d-cite>.</li>
  <li> Bias field correction is applied using N4ITK <d-cite key="tustison_n4itk_2010"></d-cite>.</li>
  <li> T1w images are linearly registered to the MNI standard space <d-cite key="fonov_unbiased_2009"></d-cite> with ANTS <d-cite key="avants_insight_2014"></d-cite> and cropped. This produced images of size 169x208x179 with 1mm3 isotropic voxels.</li>
  <li> An automatic quality check is performed using an open-source pretrained network <d-cite key="fonov_deep_2018"></d-cite>. All images passed the quality check.</li>
  <li> NIfTI files are converted to tensor format.</li>
  <li> (Optional) Images are down-sampled using a trilinear interpolation, leading to an image size of 84x104x89.</li>
  <li> Intensity rescaling between the minimum and maximum values of each image is performed.</li>
</dl>

<h4 id="classifier">Classifier</h4>

<p align="justify">
To perform such classification task a CNN was used with two different paradigms to choose the architecture. First, the authors reused the same architecture as in <d-cite key="wen_convolutional_2020"></d-cite> which was obtained by optimizing manually the networks on the ADNI data set for the same task (AD vs CN). A slight adaption was done for the down-sampled images, which consisted in resizing the number of nodes in the fully-connected layers to keep the same ratio between the input and output feature maps in all layers. This  architecture is denoted <b>baseline</b>. Secondly, a random search was launched  <d-cite key="bergstra_random_2012"></d-cite> allowing to explore different hyperperameter values. The hyperparameters explored for the architecture were the number of convolutional blocks, of filters in the first layer and of convolutional layers in a block, the number of fully-connected layers and the dropout rate. Other hyperparameters such as the learning rate and the weight decay were also part of the search. 100 different random architectures were trained on the 5-fold cross-validation done on <i>train-full</i>. For each input, the selected  architecture is the one that obtained the best mean balanced accuracy across the validation sets of the cross-validation. This architecture is referred to as <b>optimized</b>.</p>
<div class="img">
    <div class="col-sm mt-0 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/pyraug_project/CNNs.jpeg" alt="" title="CNN Networks" />
    </div>
</div>
<div class="caption">
    CNN architectures: <i>left</i>: The baseline net. <i>right</i>: The optimized one using a random search across100 architectures.
</div>

<h4 id="augmentation-set-up">Augmentation Set up</h4>

<p align="justify">
On the meantime, a RHVAE was trained on each class of the train sets (<i>train-50</i> or <i>train-full</i>) to be able to generate new synthetic data. Noteworthy is the fact that the VAE and the CNN shared the <b>same training set</b> and no augmentation was performed on the validation set or the test set.
</p>

<div class="img">
    <div class="col-sm mt-0 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/pyraug_project/DA_diagram.png" alt="" title="DA framework" />
    </div>
</div>
<div class="caption">
    Data Augmentation scheme with a VAE.
</div>

<p align="justify">
Then the <b>baseline</b> (resp. <b>optimized</b>) CNN networks were then trained for 100 (resp. 50) epochs using the cross entropy loss for training and validation losses. Balanced accuracy was also computed at the end of each epoch. The models were trained on either 1) only the <i>real</i> images; 2) only the synthetic samples created by the RHVAE or 3) the augmented training set (<i>real</i> + synthetic) on 20 independent runs for each experiment. The final model  was chosen as the one that obtained the highest validation balanced accuracy during training.  
</p>

<h4 id="results">Results</h4>

<p align="justify">
Below are presented some of the main results obtained in this case study. We refer the reader to <d-cite key="chadebec_data_2021"></d-cite> for the full results of the study.
<div class="container">
  <input type="checkbox" id="zoomCheck1" />
    <label for="zoomCheck1">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/pyraug_project/baseline_results.png" alt="zoom" title="Classification results" />
    </label>
</div>
<div class="caption">
    Augmentation results with the <b>baseline</b> CNN network.
</div>


<div class="container">
  <input type="checkbox" id="zoomCheck2" />
    <label for="zoomCheck2">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/pyraug_project/optimized_results.png" alt="zoom" title="Classification results" />
    </label>
</div>
<div class="caption">
    Augmentation results with the <b>optimized</b> CNN network.
</div>

<p align="justify">
<a href="https://github.com/clementchadebec/pyraug" target="blank">Pyraug software</a> allowed for a significant gain in the model classification results even when the CNN was optimized on the real data only (random search not performed for augmented data set) and even though small size data sets were considered along with very challenging high dimensional data.
</p>
</p>]]></content><author><name>Cl√©ment Chadebec</name></author><summary type="html"><![CDATA[Use of Pyraug software to perform MRI classification]]></summary></entry></feed>